

import sys
import os
from pathlib import Path

# Ajouter le rÃ©pertoire du projet au path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_data_cleaner_structure():
    """Test de la structure du data_cleaner.py pour Heures 9-12."""
    print("=" * 60)
    print("TEST 1: Structure data_cleaner.py (Heures 9-12)")
    print("=" * 60)
    
    # VÃ©rifier que le fichier existe
    cleaner_file = Path("data_cleaner.py")
    if not cleaner_file.exists():
        print("âŒ data_cleaner.py not found")
        return False
    
    print("âœ… data_cleaner.py found")
    
    # Lire le contenu
    with open(cleaner_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # VÃ©rifier les Ã©lÃ©ments requis pour Heures 9-12
    required_elements = {
        'class DataCleaner': 'Classe principale',
        'def remove_nulls': 'Nettoyage donnÃ©es nulles',
        'def unify_formats': 'Normalisation formats colonnes', 
        'def encode_categoricals': 'Encodage variables catÃ©gorielles',
        'def clean_pipeline': 'Pipeline complet',
        'strategy': 'StratÃ©gies de nettoyage',
        'smart': 'StratÃ©gie intelligente',
        'ordinal': 'Encodage ordinal',
        'one_hot': 'Encodage one-hot'
    }
    
    missing_elements = []
    found_elements = []
    
    for element, description in required_elements.items():
        if element in content:
            found_elements.append(f"âœ… {description}")
        else:
            missing_elements.append(f"âŒ {description}")
    
    # Afficher les rÃ©sultats
    for element in found_elements:
        print(f"  {element}")
    
    for element in missing_elements:
        print(f"  {element}")
    
    success_rate = len(found_elements) / len(required_elements) * 100
    print(f"\nðŸ“Š Couverture des exigences: {success_rate:.1f}%")
    
    return success_rate >= 80

def test_null_handling_implementation():
    """Test de l'implÃ©mentation du nettoyage des nulls."""
    print("\n" + "=" * 60)
    print("TEST 2: ImplÃ©mentation nettoyage nulls")
    print("=" * 60)
    
    with open("data_cleaner.py", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # VÃ©rifier les stratÃ©gies de nettoyage des nulls
    null_strategies = {
        'smart': 'StratÃ©gie intelligente',
        'drop': 'Suppression des nulls',
        'fill': 'Remplissage des nulls',
        '_smart_null_handling': 'MÃ©thode smart',
        '_drop_null_handling': 'MÃ©thode drop',
        '_fill_null_handling': 'MÃ©thode fill'
    }
    
    implemented_strategies = []
    missing_strategies = []
    
    for strategy, description in null_strategies.items():
        if strategy in content:
            implemented_strategies.append(f"âœ… {description}")
        else:
            missing_strategies.append(f"âŒ {description}")
    
    for strategy in implemented_strategies:
        print(f"  {strategy}")
    
    for strategy in missing_strategies:
        print(f"  {strategy}")
    
    success_rate = len(implemented_strategies) / len(null_strategies) * 100
    print(f"\nðŸ“Š ImplÃ©mentation nulls: {success_rate:.1f}%")
    
    return success_rate >= 70

def test_format_normalization():
    """Test de la normalisation des formats."""
    print("\n" + "=" * 60)
    print("TEST 3: Normalisation formats colonnes")
    print("=" * 60)
    
    with open("data_cleaner.py", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # VÃ©rifier les Ã©lÃ©ments de normalisation
    format_elements = {
        'unify_formats': 'MÃ©thode principale',
        'date': 'Normalisation dates',
        'montant': 'Normalisation montants',
        'text': 'Normalisation texte',
        'lower': 'Conversion minuscules',
        'strip': 'Suppression espaces',
        'to_datetime': 'Conversion dates'
    }
    
    implemented_formats = []
    missing_formats = []
    
    for element, description in format_elements.items():
        if element in content:
            implemented_formats.append(f"âœ… {description}")
        else:
            missing_formats.append(f"âŒ {description}")
    
    for fmt in implemented_formats:
        print(f"  {fmt}")
    
    for fmt in missing_formats:
        print(f"  {fmt}")
    
    success_rate = len(implemented_formats) / len(format_elements) * 100
    print(f"\nðŸ“Š Normalisation formats: {success_rate:.1f}%")
    
    return success_rate >= 60

def test_categorical_encoding():
    """Test de l'encodage des variables catÃ©gorielles."""
    print("\n" + "=" * 60)
    print("TEST 4: Encodage variables catÃ©gorielles")
    print("=" * 60)
    
    with open("data_cleaner.py", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # VÃ©rifier les types d'encodage
    encoding_types = {
        'encode_categoricals': 'MÃ©thode principale',
        'ordinal': 'Encodage ordinal',
        'one_hot': 'Encodage one-hot',
        'statut_encoded': 'Encodage statut',
        'get_dummies': 'Variables dummy',
        'map': 'Mapping de valeurs',
        'status_mapping': 'Mapping statut'
    }
    
    implemented_encoding = []
    missing_encoding = []
    
    for element, description in encoding_types.items():
        if element in content:
            implemented_encoding.append(f"âœ… {description}")
        else:
            missing_encoding.append(f"âŒ {description}")
    
    for enc in implemented_encoding:
        print(f"  {enc}")
    
    for enc in missing_encoding:
        print(f"  {enc}")
    
    success_rate = len(implemented_encoding) / len(encoding_types) * 100
    print(f"\nðŸ“Š Encodage catÃ©goriel: {success_rate:.1f}%")
    
    return success_rate >= 70

def test_pipeline_integration():
    """Test de l'intÃ©gration du pipeline."""
    print("\n" + "=" * 60)
    print("TEST 5: IntÃ©gration pipeline (Heures 13-16)")
    print("=" * 60)
    
    with open("data_cleaner.py", 'r', encoding='utf-8') as f:
        content = f.read()
    
    # VÃ©rifier l'intÃ©gration du pipeline
    pipeline_elements = {
        'clean_pipeline': 'Pipeline principal',
        'cleaning_stats': 'Statistiques de nettoyage',
        'cleaning_steps': 'Ã‰tapes de nettoyage',
        'get_cleaning_report': 'Rapport de nettoyage',
        'logger': 'Logging',
        'original_shape': 'Forme originale',
        'final_shape': 'Forme finale'
    }
    
    integrated_elements = []
    missing_elements = []
    
    for element, description in pipeline_elements.items():
        if element in content:
            integrated_elements.append(f"âœ… {description}")
        else:
            missing_elements.append(f"âŒ {description}")
    
    for elem in integrated_elements:
        print(f"  {elem}")
    
    for elem in missing_elements:
        print(f"  {elem}")
    
    success_rate = len(integrated_elements) / len(pipeline_elements) * 100
    print(f"\nðŸ“Š IntÃ©gration pipeline: {success_rate:.1f}%")
    
    return success_rate >= 80

def test_code_quality():
    """Test de la qualitÃ© du code."""
    print("\n" + "=" * 60)
    print("TEST 6: QualitÃ© du code")
    print("=" * 60)
    
    with open("data_cleaner.py", 'r', encoding='utf-8') as f:
        content = f.read()
        lines = content.split('\n')
    
    # Analyser la qualitÃ©
    quality_metrics = {
        'docstrings': content.count('"""') + content.count("'''"),
        'comments': len([line for line in lines if line.strip().startswith('#')]),
        'error_handling': content.count('try:') + content.count('except'),
        'logging': content.count('logger.'),
        'type_hints': content.count(': ') + content.count('->'),
        'code_lines': len([line for line in lines if line.strip() and not line.strip().startswith('#')])
    }
    
    print(f"ðŸ“Š MÃ©triques de qualitÃ©:")
    print(f"  Docstrings: {quality_metrics['docstrings']}")
    print(f"  Commentaires: {quality_metrics['comments']}")
    print(f"  Gestion d'erreurs: {quality_metrics['error_handling']}")
    print(f"  Logging: {quality_metrics['logging']}")
    print(f"  Type hints: {quality_metrics['type_hints']}")
    print(f"  Lignes de code: {quality_metrics['code_lines']}")
    
    # Score de qualitÃ©
    quality_score = 0
    if quality_metrics['docstrings'] >= 4: quality_score += 20
    if quality_metrics['comments'] >= 10: quality_score += 15
    if quality_metrics['error_handling'] >= 3: quality_score += 20
    if quality_metrics['logging'] >= 5: quality_score += 20
    if quality_metrics['code_lines'] >= 200: quality_score += 25
    
    print(f"\nðŸŽ¯ Score de qualitÃ©: {quality_score}/100")
    
    return quality_score >= 70

def main():
    """ExÃ©cuter la validation des Heures 9-12 et 13-16."""
    print("ðŸš€ Validation Heures 9-12 et 13-16")
    print("=" * 70)
    print("Focus: data_cleaner.py et validation pipeline")
    print("=" * 70)
    
    results = []
    
    # Tests ciblÃ©s
    tests = [
        ("Structure data_cleaner.py", test_data_cleaner_structure),
        ("Nettoyage nulls", test_null_handling_implementation),
        ("Normalisation formats", test_format_normalization),
        ("Encodage catÃ©goriel", test_categorical_encoding),
        ("IntÃ©gration pipeline", test_pipeline_integration),
        ("QualitÃ© du code", test_code_quality)
    ]
    
    for test_name, test_func in tests:
        print(f"\nðŸ§ª Running: {test_name}")
        try:
            result = test_func()
            results.append(result)
        except Exception as e:
            print(f"âŒ Test failed: {str(e)}")
            results.append(False)
    
    # RÃ©sumÃ© final
    print("\n" + "=" * 70)
    print("ðŸ“Š RÃ‰SULTATS VALIDATION HEURES 9-12 et 13-16")
    print("=" * 70)
    
    passed = sum(results)
    total = len(results)
    
    for i, (test_name, _) in enumerate(tests):
        status = "âœ… PASS" if results[i] else "âŒ FAIL"
        print(f"  {test_name}: {status}")
    
    print(f"\nðŸŽ¯ Score global: {passed}/{total} tests ({passed/total*100:.1f}%)")
    
    # Ã‰valuation finale
    if passed >= 5:
        print("ðŸŽ‰ VALIDATION RÃ‰USSIE!")
        print("âœ… Heures 9-12: data_cleaner.py implÃ©mentÃ© correctement")
        print("âœ… Heures 13-16: Pipeline validÃ© et fonctionnel")
        print("ðŸ“‹ PrÃªt pour la suite du dÃ©veloppement")
    elif passed >= 4:
        print("âš ï¸  VALIDATION PARTIELLE")
        print("ðŸ”§ Quelques amÃ©liorations nÃ©cessaires")
    else:
        print("âŒ VALIDATION Ã‰CHOUÃ‰E")
        print("ðŸ› ï¸  RÃ©vision nÃ©cessaire avant de continuer")
    
    return passed >= 4

if __name__ == "__main__":
    main()
