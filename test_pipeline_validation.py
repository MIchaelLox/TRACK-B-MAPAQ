
import sys
import os
from pathlib import Path
import json
from datetime import datetime

# Ajouter le r√©pertoire du projet au path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Test des imports avec fallback
PANDAS_AVAILABLE = False
NUMPY_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
    print("‚úÖ pandas available")
except ImportError:
    print("‚ö†Ô∏è  pandas not available - using fallback mode")

try:
    import numpy as np
    NUMPY_AVAILABLE = True
    print("‚úÖ numpy available")
except ImportError:
    print("‚ö†Ô∏è  numpy not available - using fallback mode")

def test_module_imports():
    """Test des imports des modules du projet."""
    print("=" * 60)
    print("TEST 1: Module Imports")
    print("=" * 60)
    
    modules_status = {}
    
    # Test data_ingest
    try:
        if PANDAS_AVAILABLE:
            from data_ingest import DataIngestor
            modules_status['data_ingest'] = "‚úÖ Full import"
        else:
            # Test import sans ex√©cution
            with open('data_ingest.py', 'r') as f:
                content = f.read()
            if 'class DataIngestor' in content:
                modules_status['data_ingest'] = "‚ö†Ô∏è  Structure OK (no pandas)"
            else:
                modules_status['data_ingest'] = "‚ùå Structure missing"
    except Exception as e:
        modules_status['data_ingest'] = f"‚ùå Error: {str(e)}"
    
    # Test data_cleaner
    try:
        if PANDAS_AVAILABLE:
            from data_cleaner import DataCleaner
            modules_status['data_cleaner'] = "‚úÖ Full import"
        else:
            with open('data_cleaner.py', 'r') as f:
                content = f.read()
            if 'class DataCleaner' in content:
                modules_status['data_cleaner'] = "‚ö†Ô∏è  Structure OK (no pandas)"
            else:
                modules_status['data_cleaner'] = "‚ùå Structure missing"
    except Exception as e:
        modules_status['data_cleaner'] = f"‚ùå Error: {str(e)}"
    
    # Test config
    try:
        from config import DataSources, LoggingConfig
        modules_status['config'] = "‚úÖ Full import"
    except Exception as e:
        modules_status['config'] = f"‚ùå Error: {str(e)}"
    
    # Afficher les r√©sultats
    for module, status in modules_status.items():
        print(f"  {module}: {status}")
    
    success_count = sum(1 for status in modules_status.values() if "‚úÖ" in status or "‚ö†Ô∏è" in status)
    return success_count >= 2

def test_pipeline_integration():
    """Test de l'int√©gration du pipeline."""
    print("\n" + "=" * 60)
    print("TEST 2: Pipeline Integration")
    print("=" * 60)
    
    if not PANDAS_AVAILABLE:
        print("‚ö†Ô∏è  Skipping functional tests - pandas not available")
        print("üìã Testing logical integration instead...")
        
        # Test logique d'int√©gration
        try:
            # V√©rifier que les modules peuvent √™tre cha√Æn√©s logiquement
            with open('data_ingest.py', 'r') as f:
                ingest_content = f.read()
            
            with open('data_cleaner.py', 'r') as f:
                cleaner_content = f.read()
            
            # V√©rifier les m√©thodes de sortie/entr√©e compatibles
            ingest_methods = ['load_raw_data', 'load_from_csv', 'load_from_url']
            cleaner_methods = ['__init__', 'clean_pipeline', 'remove_nulls']
            
            ingest_ok = all(method in ingest_content for method in ingest_methods)
            cleaner_ok = all(method in cleaner_content for method in cleaner_methods)
            
            if ingest_ok and cleaner_ok:
                print("‚úÖ Pipeline methods present")
                return True
            else:
                print("‚ùå Pipeline methods missing")
                return False
                
        except Exception as e:
            print(f"‚ùå Integration test error: {str(e)}")
            return False
    
    # Test fonctionnel complet avec pandas
    try:
        from data_ingest import DataIngestor
        from data_cleaner import DataCleaner
        
        print("üîÑ Testing full pipeline...")
        
        # √âtape 1: Ingestion
        ingestor = DataIngestor()
        
        # Cr√©er des donn√©es de test si pas d'acc√®s API
        test_data = create_sample_data()
        
        # √âtape 2: Nettoyage
        cleaner = DataCleaner(test_data)
        cleaned_data = cleaner.clean_pipeline()
        
        print(f"‚úÖ Pipeline executed: {test_data.shape} ‚Üí {cleaned_data.shape}")
        
        # V√©rifier la qualit√©
        report = cleaner.get_cleaning_report()
        quality = report['data_quality']
        
        print(f"üìä Data Quality:")
        print(f"  Completeness: {quality['completeness']:.1f}%")
        print(f"  Consistency: {quality['consistency']:.1f}%")
        
        return quality['completeness'] > 80
        
    except Exception as e:
        print(f"‚ùå Pipeline test error: {str(e)}")
        return False

def create_sample_data():
    """Cr√©er des donn√©es d'√©chantillon pour les tests."""
    if not PANDAS_AVAILABLE:
        return None
    
    sample_data = {
        'id_poursuite': [1, 2, 3, 4, 5],
        'business_id': [12345, 12346, 12347, 12348, 12349],
        'date': ['2024-01-15', '2024-02-10', '2024-01-20', '2024-01-25', '2024-02-28'],
        'date_jugement': ['2024-02-20', '2024-03-15', '2024-02-25', '2024-03-05', '2024-03-30'],
        'description': ['Temp√©rature inad√©quate', 'Contamination crois√©e', '√âquipement d√©faillant', 'Non-respect normes', 'Pr√©sence nuisibles'],
        'etablissement': ['Restaurant Le Gourmet', 'Pizzeria Mario', 'Sushi Zen', 'Caf√© Central', 'Bar Le Refuge'],
        'montant': [500, 300, 750, 400, 600],
        'proprietaire': ['Jean Dupont', 'Mario Rossi', 'Yuki Tanaka', 'Marie Tremblay', 'Pierre Leblanc'],
        'ville': ['Montr√©al', 'Montr√©al', 'Montr√©al', 'Montr√©al', 'Montr√©al'],
        'statut': ['Ouvert', 'Ouvert', 'Ouvert', 'Ferm√©', 'Ouvert'],
        'date_statut': ['2024-01-01', '2023-12-15', '2024-01-10', '2024-03-01', '2024-01-25'],
        'categorie': ['Restaurant', 'Restaurant', 'Restaurant', 'Caf√©', 'Bar']
    }
    
    return pd.DataFrame(sample_data)

def test_data_validation():
    """Test de validation des donn√©es."""
    print("\n" + "=" * 60)
    print("TEST 3: Data Validation")
    print("=" * 60)
    
    if not PANDAS_AVAILABLE:
        print("‚ö†Ô∏è  Skipping data validation - pandas not available")
        return True
    
    try:
        from data_cleaner import DataCleaner
        
        # Cr√©er des donn√©es avec probl√®mes
        problematic_data = pd.DataFrame({
            'id_poursuite': [1, None, 3, 4, 5],
            'business_id': [12345, 12346, None, 12348, 12349],
            'date': ['2024-01-15', 'invalid', '2024-01-20', None, '2024-02-28'],
            'montant': [500, 'invalid', 750, None, 600],
            'ville': ['Montr√©al', 'montreal', 'MONTREAL', None, 'Montr√©al']
        })
        
        print(f"üìä Test data with issues: {problematic_data.shape}")
        
        # Nettoyer les donn√©es
        cleaner = DataCleaner(problematic_data)
        cleaned_data = cleaner.clean_pipeline()
        
        # Valider le nettoyage
        validation_result = cleaner.validate_cleaned_data(cleaned_data)
        
        print(f"‚úÖ Validation result: {validation_result}")
        
        # V√©rifier les am√©liorations
        original_nulls = problematic_data.isnull().sum().sum()
        cleaned_nulls = cleaned_data.isnull().sum().sum()
        
        print(f"üìà Null reduction: {original_nulls} ‚Üí {cleaned_nulls}")
        
        return validation_result and cleaned_nulls < original_nulls
        
    except Exception as e:
        print(f"‚ùå Validation test error: {str(e)}")
        return False

def test_performance_metrics():
    """Test des m√©triques de performance."""
    print("\n" + "=" * 60)
    print("TEST 4: Performance Metrics")
    print("=" * 60)
    
    if not PANDAS_AVAILABLE:
        print("‚ö†Ô∏è  Skipping performance tests - pandas not available")
        return True
    
    try:
        from data_cleaner import DataCleaner
        import time
        
        # Cr√©er un dataset plus large pour le test de performance
        large_data = create_sample_data()
        # R√©pliquer les donn√©es pour simuler un dataset plus grand
        for _ in range(10):
            large_data = pd.concat([large_data, create_sample_data()], ignore_index=True)
        
        print(f"üìä Performance test data: {large_data.shape}")
        
        # Mesurer le temps de nettoyage
        start_time = time.time()
        
        cleaner = DataCleaner(large_data)
        cleaned_data = cleaner.clean_pipeline()
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"‚è±Ô∏è  Processing time: {processing_time:.2f} seconds")
        print(f"üìà Throughput: {len(large_data)/processing_time:.0f} rows/second")
        
        # V√©rifier que le temps est raisonnable (< 10 secondes pour ce test)
        performance_ok = processing_time < 10
        
        if performance_ok:
            print("‚úÖ Performance acceptable")
        else:
            print("‚ö†Ô∏è  Performance could be improved")
        
        return True  # Ne pas faire √©chouer pour la performance
        
    except Exception as e:
        print(f"‚ùå Performance test error: {str(e)}")
        return False

def test_error_handling():
    """Test de la gestion d'erreurs."""
    print("\n" + "=" * 60)
    print("TEST 5: Error Handling")
    print("=" * 60)
    
    if not PANDAS_AVAILABLE:
        print("‚ö†Ô∏è  Skipping error handling tests - pandas not available")
        return True
    
    try:
        from data_cleaner import DataCleaner
        
        # Test avec DataFrame vide
        empty_df = pd.DataFrame()
        try:
            cleaner = DataCleaner(empty_df)
            result = cleaner.clean_pipeline()
            print("‚úÖ Empty DataFrame handled gracefully")
        except Exception as e:
            print(f"‚ö†Ô∏è  Empty DataFrame error: {str(e)}")
        
        # Test avec donn√©es compl√®tement nulles
        null_df = pd.DataFrame({
            'col1': [None, None, None],
            'col2': [None, None, None]
        })
        try:
            cleaner = DataCleaner(null_df)
            result = cleaner.clean_pipeline()
            print("‚úÖ All-null DataFrame handled gracefully")
        except Exception as e:
            print(f"‚ö†Ô∏è  All-null DataFrame error: {str(e)}")
        
        # Test avec types de donn√©es incompatibles
        mixed_df = pd.DataFrame({
            'mixed_col': [1, 'text', [1,2,3], {'key': 'value'}]
        })
        try:
            cleaner = DataCleaner(mixed_df)
            result = cleaner.clean_pipeline()
            print("‚úÖ Mixed data types handled gracefully")
        except Exception as e:
            print(f"‚ö†Ô∏è  Mixed data types error: {str(e)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error handling test failed: {str(e)}")
        return False

def generate_validation_report():
    """G√©n√©rer un rapport de validation complet."""
    print("\n" + "=" * 60)
    print("PIPELINE VALIDATION REPORT")
    print("=" * 60)
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'environment': {
            'pandas_available': PANDAS_AVAILABLE,
            'numpy_available': NUMPY_AVAILABLE,
            'python_version': sys.version
        },
        'modules_status': {},
        'tests_results': {},
        'recommendations': []
    }
    
    # V√©rifier les modules
    modules = ['data_ingest.py', 'data_cleaner.py', 'config.py']
    for module in modules:
        if Path(module).exists():
            report['modules_status'][module] = 'present'
        else:
            report['modules_status'][module] = 'missing'
    
    # Recommandations bas√©es sur l'environnement
    if not PANDAS_AVAILABLE:
        report['recommendations'].append("Install pandas: python -m pip install pandas")
    if not NUMPY_AVAILABLE:
        report['recommendations'].append("Install numpy: python -m pip install numpy")
    
    # Sauvegarder le rapport
    report_path = Path('validation_report.json')
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"üìÑ Validation report saved: {report_path}")
    return report

def main():
    """Ex√©cuter la validation compl√®te du pipeline."""
    print("üöÄ Pipeline Validation - Ingestion + Cleaning")
    print("=" * 70)
    print("Heures 13-16: Validation pipeline complet")
    print("=" * 70)
    
    results = []
    
    # Tests √† ex√©cuter
    tests = [
        ("Module Imports", test_module_imports),
        ("Pipeline Integration", test_pipeline_integration),
        ("Data Validation", test_data_validation),
        ("Performance Metrics", test_performance_metrics),
        ("Error Handling", test_error_handling)
    ]
    
    for test_name, test_func in tests:
        print(f"\nüß™ Running: {test_name}")
        try:
            result = test_func()
            results.append(result)
        except Exception as e:
            print(f"‚ùå Test failed with exception: {str(e)}")
            results.append(False)
    
    # G√©n√©rer le rapport
    report = generate_validation_report()
    
    # R√©sum√© des r√©sultats
    print("\n" + "=" * 70)
    print("üìä PIPELINE VALIDATION RESULTS")
    print("=" * 70)
    
    passed = sum(results)
    total = len(results)
    
    for i, (test_name, _) in enumerate(tests):
        status = "‚úÖ PASS" if results[i] else "‚ùå FAIL"
        print(f"  {test_name}: {status}")
    
    print(f"\nüéØ Overall: {passed}/{total} tests passed ({passed/total*100:.1f}%)")
    
    # √âvaluation finale
    if PANDAS_AVAILABLE and passed >= 4:
        print("üéâ PIPELINE VALIDATION SUCCESSFUL!")
        print("‚úÖ Ready for Heures 17-20: Encodage des variables cat√©gorielles")
    elif not PANDAS_AVAILABLE and passed >= 2:
        print("‚ö†Ô∏è  PARTIAL VALIDATION SUCCESSFUL!")
        print("üìã Install dependencies for full validation")
        print("üí° Next: Install pandas/numpy, then proceed to Heures 17-20")
    else:
        print("‚ùå PIPELINE VALIDATION FAILED!")
        print("üîß Review implementation before proceeding")
    
    return passed >= (4 if PANDAS_AVAILABLE else 2)

if __name__ == "__main__":
    main()
