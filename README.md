# Track B â€“ MAPAQ Predictive Health Model

Goal: Predict restaurant risk profiles based on public inspection datasets + derived variables.

Dataset Preparation

- Collect MAPAQ inspection data.
  
  --> /data_ingest.py

- Clean the dataset (remove nulls, unify column formats, encode categorical variables).
  
  --> /data_cleaner.py

Dictionaries

- Addresses Dictionary: Normalize addresses â†’ enable geocoding for map display.
  
  --> /address_dict.py

- Themes Dictionary: Build keyword-based classification system (e.g., â€œSushi,â€ â€œTrattoria,â€ â€œBBQâ€) to infer cuisine type.
  
  --> /theme_dict.py

Probability Model

- Implement baseline model (logistic regression or NaÃ¯ve Bayes).
  
  --> /model_baseline.py

- Calculate conditional probabilities for infractions given variables (theme, size, past history).
  
  --> /probability_engine.py

Rule Adaptation

- Add logic to adjust probabilities when regulations change (store effective dates in DB, apply time-based weights).
  
  --> /rule_adapter.py

Risk Profiling

- Generate risk score per restaurant.
  
  --> /risk_score.py

- Categorize into Low / Medium / High risk.
  
  --> /risk_categorizer.py

Visualization

- Build dashboard showing probabilities and trends.
  
  --> /dashboard.py (Flask/Django + frontend framework)

- Map restaurants (using geocoded addresses).
  
  --> /geo_map.py

---

## ğŸš€ Dashboard Interactif (AjoutÃ© par Grace MANDIANGU)

### Serveur API REST

- Serveur Flask avec endpoints API complets pour le dashboard interactif.
  
  --> /app_server.py
  
  **FonctionnalitÃ©s :**
  - 8 endpoints API REST (dashboard, restaurants, charts, prÃ©dictions)
  - 15 restaurants de dÃ©monstration gÃ©nÃ©rÃ©s automatiquement
  - Support CORS intÃ©grÃ©
  - Gestion d'erreurs robuste
  - Compatible avec ou sans base de donnÃ©es

### Interface Web Interactive

- Dashboard web moderne avec actualisation en temps rÃ©el.
  
  --> /mapaq_dashboard.html
  
  **FonctionnalitÃ©s :**
  - Statistiques en temps rÃ©el (4 cartes animÃ©es)
  - Graphiques interactifs (Chart.js) : distribution et tendances
  - Tableau dynamique avec recherche et tri
  - Actualisation automatique toutes les 30 secondes
  - Design responsive et moderne
  - Appels AJAX pour chargement des donnÃ©es

### Utilisation Rapide

```bash
# DÃ©marrer le serveur Flask
python app_server.py

# Puis ouvrir dans le navigateur
http://127.0.0.1:5000
```

### API Endpoints Disponibles

- `GET /api/v1/dashboard` - Statistiques globales
- `GET /api/v1/restaurants` - Liste des restaurants (avec filtres)
- `GET /api/v1/restaurant/{id}` - DÃ©tails d'un restaurant
- `GET /api/v1/charts/distribution` - DonnÃ©es graphique distribution
- `GET /api/v1/charts/trends` - DonnÃ©es graphique tendances
- `GET /api/v1/zones` - Liste des zones disponibles
- `POST /api/v1/predict` - PrÃ©diction de risque
- `GET /api/health` - Health check du serveur

---

## ğŸ”„ Pipeline de DonnÃ©es ETL (AjoutÃ© par Grace MANDIANGU)

### Pipeline AutomatisÃ© Complet

- Pipeline ETL pour traitement automatisÃ© des donnÃ©es d'inspection MAPAQ.
  
  --> /data_pipeline.py
  
  **Ã‰tapes du Pipeline :**
  1. **Ingestion** - Chargement des donnÃ©es brutes (CSV, API, base de donnÃ©es)
  2. **Nettoyage** - Normalisation, suppression des doublons, gestion des valeurs manquantes
  3. **Enrichissement** - GÃ©ocodage, dÃ©tection de thÃ¨mes, ajout de mÃ©tadonnÃ©es
  4. **ModÃ©lisation** - Calcul des scores de risque et prÃ©dictions
  5. **Validation** - ContrÃ´le qualitÃ© avec rÃ¨gles de validation
  6. **Sauvegarde** - Insertion/mise Ã  jour dans la base de donnÃ©es SQLite
  
  **FonctionnalitÃ©s :**
  - Gestion d'erreurs avec retry automatique (3 tentatives)
  - Logging dÃ©taillÃ© de chaque Ã©tape
  - MÃ©triques d'exÃ©cution (durÃ©e, enregistrements traitÃ©s)
  - Backup automatique de la base de donnÃ©es
  - Traitement par lots (batch processing)

### Scheduler d'ExÃ©cution Automatique

- Planificateur pour exÃ©cution pÃ©riodique du pipeline.
  
  --> /pipeline_scheduler.py
  
  **Modes d'ExÃ©cution :**
  - **Quotidien** - ExÃ©cution Ã  heure fixe (ex: 02:00)
  - **Horaire** - ExÃ©cution toutes les heures
  - **Intervalle** - ExÃ©cution Ã  intervalle personnalisÃ© (ex: 30 minutes)
  - **ImmÃ©diat** - ExÃ©cution unique sur demande
  
  **Utilisation :**
  ```bash
  python pipeline_scheduler.py
  # Puis choisir l'option souhaitÃ©e (1-4)
  ```

### Module de Validation des DonnÃ©es

- Validateur avec rÃ¨gles configurables pour contrÃ´le qualitÃ©.
  
  --> /data_validator.py
  
  **Types de Validation :**
  - Champs obligatoires (nom, adresse, score)
  - Plages de valeurs (score: 0-100, probabilitÃ©: 0-1)
  - Ã‰numÃ©rations (catÃ©gories de risque, tailles)
  - Formats de dates (YYYY-MM-DD)
  
  **Niveaux de SÃ©vÃ©ritÃ© :**
  - **Erreur** - Bloque l'enregistrement
  - **Avertissement** - Signale mais accepte l'enregistrement
  
  **Rapport de Validation :**
  - Taux de validation
  - RÃ©sumÃ© des erreurs par type
  - Liste des enregistrements invalides

### Interface CLI pour le Pipeline

- Script en ligne de commande pour lancer le pipeline facilement.
  
  --> /run_pipeline.py
  
  **Modes d'Utilisation :**
  
  ```bash
  # Mode interactif (avec questions)
  python run_pipeline.py
  
  # Mode CLI avec options
  python run_pipeline.py --source data/raw/inspections.csv --output mapaq.db
  
  # Avec gÃ©nÃ©ration de rapport
  python run_pipeline.py --report rapport_pipeline.json
  
  # DÃ©sactiver les backups
  python run_pipeline.py --no-backup
  ```
  
  **Options Disponibles :**
  - `--source` : Chemin du fichier source
  - `--output` : Chemin de la base de donnÃ©es
  - `--backup` / `--no-backup` : Activer/dÃ©sactiver les backups
  - `--report` : GÃ©nÃ©rer un rapport JSON
  - `--interactive` : Mode interactif

### Architecture du Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DonnÃ©es Brutes â”‚ (CSV, API, DB)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ingestion     â”‚ â†’ Chargement des donnÃ©es
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nettoyage     â”‚ â†’ Normalisation, validation basique
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enrichissement  â”‚ â†’ GÃ©ocodage, thÃ¨mes, mÃ©tadonnÃ©es
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ModÃ©lisation   â”‚ â†’ Scores de risque, prÃ©dictions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Validation    â”‚ â†’ ContrÃ´le qualitÃ©, rÃ¨gles mÃ©tier
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Sauvegarde    â”‚ â†’ Base de donnÃ©es SQLite
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dashboard     â”‚ â†’ Visualisation temps rÃ©el
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ExÃ©cution ComplÃ¨te du Pipeline

**Ã‰tape 1 : ExÃ©cution Manuelle**
```bash
# Lancer le pipeline une fois
python run_pipeline.py

# Ou avec options spÃ©cifiques
python run_pipeline.py --source data/raw/mapaq_data.csv --report rapport.json
```

**Ã‰tape 2 : Automatisation avec Scheduler**
```bash
# Lancer le scheduler
python pipeline_scheduler.py

# Choisir l'option:
# 1 = Quotidien Ã  02:00
# 2 = Toutes les heures
# 3 = Toutes les 30 minutes
# 4 = ExÃ©cution immÃ©diate
```

**Ã‰tape 3 : Visualisation**
```bash
# DÃ©marrer le dashboard pour voir les rÃ©sultats
python app_server.py

# Ouvrir http://127.0.0.1:5000
```

### Logs et Monitoring

Le pipeline gÃ©nÃ¨re automatiquement :
- **pipeline.log** - Logs dÃ©taillÃ©s de chaque exÃ©cution
- **data/backups/** - Backups de la base de donnÃ©es
- **Rapports JSON** - MÃ©triques et statistiques d'exÃ©cution

### Gestion des Erreurs

Le pipeline inclut :
- âœ… Retry automatique (3 tentatives par Ã©tape)
- âœ… Rollback en cas d'erreur de sauvegarde
- âœ… Logs dÃ©taillÃ©s pour debugging
- âœ… Continuation partielle (traite ce qui est valide)
- âœ… Notifications d'erreurs critiques

### Configuration

Le pipeline utilise des valeurs par dÃ©faut mais peut Ãªtre configurÃ© :

```python
from data_pipeline import PipelineConfig

config = PipelineConfig(
    source_data_path="data/raw/inspections.csv",
    output_db_path="mapaq_dashboard.db",
    backup_enabled=True,
    max_retries=3,
    batch_size=100
)
```
